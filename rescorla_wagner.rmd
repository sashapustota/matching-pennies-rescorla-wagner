---
title: "Portfolio2"
output: html_document
date: "2024-02-22"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
set.seed(420)
```

# Info on the model - notes
The "choice" object is part of the model's input data. It represents the actual choices made by subjects in each trial, as observed in the dataset. These are real-world observations that the model is trying to understand and predict.

"choice_sim", on the other hand, is a simulated output generated by the model. It represents hypothetical choices that could be made by subjects under the same conditions, based on the parameter values estimated by the model. These simulated choices are generated after the model parameters have been estimated, using the stochastic processes defined in the generated quantities block.

The "choice" data is used to fit the model. It's part of the observed data against which the model parameters (alpha and tau) are estimated. The model tries to explain these observed choices based on the underlying decision-making process it represents.

"choice_sim" is used for prediction and validation. After the model parameters have been estimated, choice_sim can be generated to simulate how the model believes subjects would behave under similar conditions. This can be useful for model validation (comparing simulated choices to actual choices not used in fitting the model) or for predicting future behavior under hypothetical scenarios.

```{r}
library(pacman)
pacman::p_load(rstan,
               ggplot2)


```

# Simulating data
**Rescorla-Wagner** in R.
```{r simulate_responses}
# -------- PARAMS TO RUN SETTINGS, UNHASH TO GET SPECIFICS
# Parameters
#tau <- 2  # Temperature parameter for softmax function
#alpha <- 0.3  # Learning rate

# # High-High
# tau <- 9
# alpha <- 0.8

# # Low-Low
# tau <- 0.5
# alpha <- 0.1

# # High-Low
# tau <- 9
# alpha <- 0.1

# Low-High
# tau <- 0.5
# alpha <- 0.8

# ------------------------------------


# Defining function for getting agent + opponent responses
simulate_agents_resp <- function(trials,              # Number of trials
                                 alpha,               # Learning Rate
                                 tau,                 # Inverse temperature
                                 opponent_bias){      # Put opponent's bias here (e.g. 0.7, 0.5...)
  
  # First, generate opponent's choices
  opponent_choices <- rbinom(n = trials, 
                             size = 1, 
                             prob = opponent_bias)
  
  # Initialize values
  choice <- numeric(length(opponent_choices)) # initializing a vector of zeros the length of how many choices we have
  choice[1] <- rbinom(1,
                      size = 1, 
                      prob = 0.5)  # First choice randomly sampled
  
  # ----- The Recorla-Wagner model
  # Initialize values for the Rescorla-Wagner model
  v <- c(0.5, 
         0.5)  # Initial values for the agent's choices (heads and tails)
  
  rewards <- numeric(length(opponent_choices)) # initializing a vector of zeros the length of how many choices we have
  
  # Simulate agent's responses
  for (t in 2:length(opponent_choices)) {  # Starting from the second round
    
    # Calculate reward
    if (opponent_choices[t - 1] == choice[t - 1]) {
      reward <- 1
    } else {
      reward <- 0
    }
    rewards[t - 1] <- reward
    
    # Rescorla-Wagner model
    pe <- rewards[t - 1] - v[choice[t - 1] + 1]
    
    v[choice[t - 1] + 1] <- v[choice[t - 1] + 1] + alpha * pe
    
    # Update choice based on softmax
    prob_head <- 1 - exp(tau * v[1]) / (exp(tau * v[1]) + exp(tau * v[2]))
    choice[t] <- rbinom(1, size = 1, prob = prob_head)
  }
  
  # Display the rewards, choices, and updated values
  print(rewards)
  print(choice)
  print(mean(choice))
  print(v)
  
  choice = choice + 1
  print(mean(choice))
  
  ## Create the data. N.B. note the two variables have different lengths: 1 for n, n for h.
  data <- list(
  nTrials = trials,  # n of trials
  choice = choice,
  reward = rewards)
  
  return(list(data = data, tau = tau, alpha = alpha))

}

result = simulate_agents_resp(trials = 120,
                             alpha = 0.6,
                             tau = 5,
                             opponent_bias = 0.7)


data = result$data
alpha = result$alpha
tau = result$tau

```

Before fitting the model to the data, let's do a prior predictive check, to ensure our priors are adequate.

```{r}

library(rethinking)

alpha_prior <- runif(1e4 , 0, 1)
dens(alpha_prior)

tau_prior <- runif(1e4, 0, 10)
dens(tau_prior)

# As the 'rethinking' package messes up with fitting the STAN model to the data in the next chunk, we unload it.
pacman::p_unload(rethinking)

```


### If you want to run the model just once, use this chunk (otherwise see recovery chunks further down)
```{r}
modelFile <- 'RW.stan'

# Setting specs for modelling
nIter     <- 2000
nChains   <- 4 
nWarmup   <- floor(nIter/2)
nThin     <- 1

# Timing statements
cat("Estimating", modelFile, "model... \n")
startTime = Sys.time(); print(startTime)
cat("Calling", nChains, "simulations in Stan... \n")

# Fitting model
fit_rl <- stan(modelFile, 
               data    = data, 
               chains  = nChains,
               iter    = nIter,
               warmup  = nWarmup,
               thin    = nThin,
               init    = "random",
               seed    = 1450154626)

# Timing statements
cat("Finishing", modelFile, "model simulation ... \n")
endTime = Sys.time()
print(endTime)

# Corrected time difference display
time_difference <- endTime - startTime
cat("It took", as.numeric(time_difference, units = "secs"), "seconds\n")

```

## Inspect model
```{r}
# Get summary of model
print(fit_rl)

summary(fit_rl)
    
# Trace
plot_trace_excl_warm_up <- stan_trace(fit_rl, 
                                      pars = c('alpha','tau'), 
                                      inc_warmup = F)

plot_trace_excl_warm_up

plot_dens <- stan_plot(
  fit_rl,
  pars = c('alpha',
           'tau',
           'alpha_prior',
           'tau_prior'),
  show_density = T,
  fill_color = 'skyblue',
  alpha = 0.15
) +
  geom_vline(
    xintercept = tau,
    color = "orange",
    linetype = "dashed",
    linewidth = 1.5
  ) +
  geom_vline(
    xintercept = alpha,
    color = "forestgreen",
    linetype = "dashed",
    linewidth = 1.5
  )+
  labs(title = "Parameter Recovery", # Remember to change setting depending on what youre running
           subtitle = "Tau (orange): 2, Alpha (green): 0.6") +
  theme(plot.title = element_text(face = "bold"))


plot_dens

```

# Prior / Predictive checks

```{r}
# Extract simulated choice data from model output
posterior_choices <- extract(fit_rl)$choice_sim

# Calculate summary statistics or visualize these choices if you want to
# For example, comparing the mean of the simulated choices to the observed mean
observed_mean <- mean(data$choice)
simulated_means <- apply(posterior_choices, 
                         2, 
                         mean)

print(observed_mean)
print(mean(simulated_means))
```

## Alpha prior-post-plots

```{r}

# The fit_rl is our fitted Stan model object
posterior_alpha <- extract(fit_rl)$alpha

# Sample from the prior distribution for alpha
prior_alpha <- rbeta(10000, 1, 1)  # beta(1, 1) prior

# Create a data frame for ggplot
alpha_data <- data.frame(
  value = c(prior_alpha, posterior_alpha),
  distribution = factor(c(rep("Prior", length(prior_alpha)), rep("Posterior", length(posterior_alpha))))
)

# Plot with ggplot2
ggplot(alpha_data, aes(x = value, fill = distribution)) +
  geom_density(alpha = 0.5) +
  scale_fill_manual(values = c("blue", "green")) +
  labs(title = "Prior vs Posterior Distributions of Alpha",
       subtitle = "Model has learnt - posterior has become more peaked, 
and is within the prior's range.",
       x = "Alpha",
       y = "Density") +
  theme_minimal()+
  theme(plot.title = element_text(face = "bold"))

```

## Tau prior-post-plots

```{r}
# Extract the posterior samples for tau
posterior_tau <- extract(fit_rl)$tau

# Sample from the prior distribution for tau
prior_tau <- runif(10000, 0, 10)  # uniform(0, 10) prior

# Create a data frame for ggplot
tau_data <- data.frame(
  value = c(prior_tau, posterior_tau),
  distribution = factor(c(rep("Prior", length(prior_tau)), rep("Posterior", length(posterior_tau))))
)

# Plot with ggplot2
ggplot(tau_data, aes(x = value, fill = distribution)) +
  geom_density(alpha = 0.5) +
  scale_fill_manual(values = c("red", "yellow")) +
  labs(title = "Prior vs Posterior Distributions of Tau",
       subtitle = "Model has learnt - posterior has become more peaked, 
and is within the prior's range.",
       x = "Tau",
       y = "Density") +
  theme_minimal()+
  theme(plot.title = element_text(face = "bold"))

```

# Some notessssss from methods 4
When conducting a prior-posterior check, we wanna see how the data (evidence) has updated our initial beliefs (priors) to give  new beliefs (posteriors). The extent and nature of this update can give insights into the parameter's role in the model and how it relates to the observed data. It's also important to reflect on whether the posterior distributions make sense given our understanding of the process being modeled. If the posteriors are surprising or counterintuitive, it may warrant a deeper examination of both the data and the model's structure..

### Prior-Posterior checks interpretation:
Informative data: The shift from the prior to the posterior distributions in both parameters indicates that our data is informative and is significantly updating our beliefs about the parameters.

Model fit: The lack of overlap between prior and posterior for tau suggests that the data has provided substantial information to update the beliefs about this parameter.

Conclusions: The model has learned specific characteristics about the learning rate and the temperature parameter from the data, which can be interpreted in the context of the behavior or process we are modeling.

# Parameter Recovery Plots

```{r}
library(tidyverse)
d <- NULL

for (alpha in seq(0, 1, 0.1)) { # looping through alpha levels

  for (tau in seq(0, 10, 0.5)) { # looping through tau levels
    
    # list of three
    random_choice <- simulate_agents_resp(trials = 120,
                                          alpha = alpha,
                                          tau = tau,
                                          opponent_bias = 0.5)
    
    temp <- tibble(nTrials = seq(random_choice$nTrials), 
                   choice = random_choice$choice, alpha, tau,
                   reward = random_choice$reward)
    
    #temp$cumulativerate <- cumsum(temp$choice) / seq_along(temp$choice)

    if (exists("d")) {
      d <- rbind(d, temp)
    } else{
      d <- temp
    }
  }
}

# Now we need to scale it up to all possible rates and noises
recovery_df <- NULL

for (alphaLvl in unique(d$alpha)) {
  
  for (tauLvl in unique(d$tau)) {
    
    dd <- d %>% subset(
      alpha == alphaLvl  & tau == tauLvl
    )
    
    data <- list(
      nTrials = max(dd$nTrials),
      choice = dd$choice,
      reward = dd$reward
      
    )
    
    # Get modelling stuff
    modelFile <- 'RW.stan'
    
    nIter     <- 2000
    nChains   <- 4 
    nWarmup   <- floor(nIter/2)
    nThin     <- 1
    
    samples <- stan(modelFile, 
                   data    = data, 
                   chains  = nChains,
                   iter    = nIter,
                   warmup  = nWarmup,
                   thin    = nThin,
                   init    = "random",
                   seed    = 1450154626)
    
    # Get the posteriors out, estimated and true values
    temp <- tibble(tauEst = rstan::extract(samples)$tau,
                   alphaEst = rstan::extract(samples)$alpha,
                   
                   tauTrue = tauLvl, 
                   alphaTrue = alphaLvl)
    
    
    if (exists("recovery_df")) {recovery_df <- rbind(recovery_df, temp)} else {recovery_df <- temp}
    
  }
  
}

recovery_df

#write_csv(recovery_df, "recoverydf_tau_alpha.csv")
```

## Recovery plots

```{r}
# Tau plot
ggplot(recovery_df,
       
       aes(tauTrue,
           tauEst))+
  
  geom_point(alpha = 0.1)+
  geom_smooth()+
  facet_wrap(.~alphaTrue)+
  theme_minimal()

# Alpha plot
ggplot(recovery_df,
       
       aes(alphaTrue,
           alphaEst))+
  
  geom_point(alpha = 0.1)+
  geom_smooth()+
  facet_wrap(.~tauTrue)+
  theme_minimal()

```

